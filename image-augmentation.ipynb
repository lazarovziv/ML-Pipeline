{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e0b73ded70a3ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:49.173514Z",
     "start_time": "2025-01-13T13:08:49.170708Z"
    },
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:09.516631Z",
     "iopub.status.busy": "2024-10-03T20:38:09.515625Z",
     "iopub.status.idle": "2024-10-03T20:38:09.521232Z",
     "shell.execute_reply": "2024-10-03T20:38:09.520275Z",
     "shell.execute_reply.started": "2024-10-03T20:38:09.516573Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b03c857b6803605e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:49.183437Z",
     "start_time": "2025-01-13T13:08:49.180519Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:09.524053Z",
     "iopub.status.busy": "2024-10-03T20:38:09.523375Z",
     "iopub.status.idle": "2024-10-03T20:38:09.532130Z",
     "shell.execute_reply": "2024-10-03T20:38:09.531207Z",
     "shell.execute_reply.started": "2024-10-03T20:38:09.524016Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa6f31ec018e4db6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:49.191598Z",
     "start_time": "2025-01-13T13:08:49.189441Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:09.534002Z",
     "iopub.status.busy": "2024-10-03T20:38:09.533368Z",
     "iopub.status.idle": "2024-10-03T20:38:09.541887Z",
     "shell.execute_reply": "2024-10-03T20:38:09.541008Z",
     "shell.execute_reply.started": "2024-10-03T20:38:09.533954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_data_dir = './data/alzheimer'\n",
    "train_base_dir = f'{base_data_dir}/train'\n",
    "test_base_dir = f'{base_data_dir}/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db2ae93f811fd1ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:49.198742Z",
     "start_time": "2025-01-13T13:08:49.195604Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:09.543361Z",
     "iopub.status.busy": "2024-10-03T20:38:09.543030Z",
     "iopub.status.idle": "2024-10-03T20:38:09.564780Z",
     "shell.execute_reply": "2024-10-03T20:38:09.564077Z",
     "shell.execute_reply.started": "2024-10-03T20:38:09.543317Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_distributions = {}\n",
    "classes = os.listdir(train_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32c830867e126cd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:49.209170Z",
     "start_time": "2025-01-13T13:08:49.201746Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:09.567200Z",
     "iopub.status.busy": "2024-10-03T20:38:09.566898Z",
     "iopub.status.idle": "2024-10-03T20:38:09.575164Z",
     "shell.execute_reply": "2024-10-03T20:38:09.574401Z",
     "shell.execute_reply.started": "2024-10-03T20:38:09.567166Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for class_name in classes:\n",
    "    class_distributions[class_name] = len(os.listdir(f'{train_base_dir}/{class_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934da62513157476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:49.216631Z",
     "start_time": "2025-01-13T13:08:49.212276Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:09.576595Z",
     "iopub.status.busy": "2024-10-03T20:38:09.576278Z",
     "iopub.status.idle": "2024-10-03T20:38:09.582887Z",
     "shell.execute_reply": "2024-10-03T20:38:09.581929Z",
     "shell.execute_reply.started": "2024-10-03T20:38:09.576562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7a145a8f97c653f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:49.488210Z",
     "start_time": "2025-01-13T13:08:49.479915Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:09.584673Z",
     "iopub.status.busy": "2024-10-03T20:38:09.584046Z",
     "iopub.status.idle": "2024-10-03T20:38:09.590890Z",
     "shell.execute_reply": "2024-10-03T20:38:09.589954Z",
     "shell.execute_reply.started": "2024-10-03T20:38:09.584625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9354c5769f1843f",
   "metadata": {},
   "source": [
    "#### Distribution of classes in the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151dddf3d45595f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:49.701506Z",
     "start_time": "2025-01-13T13:08:49.540724Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:09.592412Z",
     "iopub.status.busy": "2024-10-03T20:38:09.592042Z",
     "iopub.status.idle": "2024-10-03T20:38:09.819926Z",
     "shell.execute_reply": "2024-10-03T20:38:09.818984Z",
     "shell.execute_reply.started": "2024-10-03T20:38:09.592366Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.bar(classes, class_distributions.values())\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e085dfeed61b388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:49.709019Z",
     "start_time": "2025-01-13T13:08:49.706552Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:09.821674Z",
     "iopub.status.busy": "2024-10-03T20:38:09.821334Z",
     "iopub.status.idle": "2024-10-03T20:38:09.826071Z",
     "shell.execute_reply": "2024-10-03T20:38:09.825079Z",
     "shell.execute_reply.started": "2024-10-03T20:38:09.821638Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d81b08633acbca89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:49.725262Z",
     "start_time": "2025-01-13T13:08:49.722203Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:09.827780Z",
     "iopub.status.busy": "2024-10-03T20:38:09.827430Z",
     "iopub.status.idle": "2024-10-03T20:38:09.838383Z",
     "shell.execute_reply": "2024-10-03T20:38:09.837337Z",
     "shell.execute_reply.started": "2024-10-03T20:38:09.827744Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_image_dimensions(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    return image.width, image.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2fe94be30765c94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:49.752393Z",
     "start_time": "2025-01-13T13:08:49.743489Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:09.839974Z",
     "iopub.status.busy": "2024-10-03T20:38:09.839607Z",
     "iopub.status.idle": "2024-10-03T20:38:09.847033Z",
     "shell.execute_reply": "2024-10-03T20:38:09.846151Z",
     "shell.execute_reply.started": "2024-10-03T20:38:09.839929Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "304fb04c22c1832c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:49.757907Z",
     "start_time": "2025-01-13T13:08:49.755398Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:09.849203Z",
     "iopub.status.busy": "2024-10-03T20:38:09.848392Z",
     "iopub.status.idle": "2024-10-03T20:38:09.856167Z",
     "shell.execute_reply": "2024-10-03T20:38:09.855455Z",
     "shell.execute_reply.started": "2024-10-03T20:38:09.849156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_dimensions_distributions = {\n",
    "    'width': [],\n",
    "    'height': [],\n",
    "    'class': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbff717caf6faac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:55.807840Z",
     "start_time": "2025-01-13T13:08:49.763289Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:09.861441Z",
     "iopub.status.busy": "2024-10-03T20:38:09.861135Z",
     "iopub.status.idle": "2024-10-03T20:38:19.512260Z",
     "shell.execute_reply": "2024-10-03T20:38:19.511337Z",
     "shell.execute_reply.started": "2024-10-03T20:38:09.861408Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for class_name in classes:\n",
    "    for image_name in tqdm(os.listdir(f'{train_base_dir}/{class_name}')):\n",
    "        image_path = f'{train_base_dir}/{class_name}/{image_name}'\n",
    "        image_width, image_height = get_image_dimensions(image_path)\n",
    "        class_dimensions_distributions['width'].append(image_width)\n",
    "        class_dimensions_distributions['height'].append(image_height)\n",
    "        class_dimensions_distributions['class'].append(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "745310fc97344b96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:55.824315Z",
     "start_time": "2025-01-13T13:08:55.813081Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:19.513825Z",
     "iopub.status.busy": "2024-10-03T20:38:19.513486Z",
     "iopub.status.idle": "2024-10-03T20:38:19.528924Z",
     "shell.execute_reply": "2024-10-03T20:38:19.527911Z",
     "shell.execute_reply.started": "2024-10-03T20:38:19.513789Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dimensions_df = pd.DataFrame(class_dimensions_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e070fac3f172b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:55.893965Z",
     "start_time": "2025-01-13T13:08:55.845989Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:19.530193Z",
     "iopub.status.busy": "2024-10-03T20:38:19.529905Z",
     "iopub.status.idle": "2024-10-03T20:38:19.545272Z",
     "shell.execute_reply": "2024-10-03T20:38:19.544406Z",
     "shell.execute_reply.started": "2024-10-03T20:38:19.530161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dimensions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf1286adad9caca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:55.912953Z",
     "start_time": "2025-01-13T13:08:55.899944Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:19.547057Z",
     "iopub.status.busy": "2024-10-03T20:38:19.546656Z",
     "iopub.status.idle": "2024-10-03T20:38:19.567442Z",
     "shell.execute_reply": "2024-10-03T20:38:19.566546Z",
     "shell.execute_reply.started": "2024-10-03T20:38:19.547014Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dimensions_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a4ba8836a62c2f",
   "metadata": {},
   "source": [
    "#### Distribution of photos' dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579ec82c1d32f79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:55.935812Z",
     "start_time": "2025-01-13T13:08:55.929093Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:19.568834Z",
     "iopub.status.busy": "2024-10-03T20:38:19.568533Z",
     "iopub.status.idle": "2024-10-03T20:38:19.576594Z",
     "shell.execute_reply": "2024-10-03T20:38:19.575646Z",
     "shell.execute_reply.started": "2024-10-03T20:38:19.568800Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dimensions_df['width'].value_counts(), dimensions_df['height'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56abcf7c521be074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:55.958218Z",
     "start_time": "2025-01-13T13:08:55.955922Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:19.577993Z",
     "iopub.status.busy": "2024-10-03T20:38:19.577661Z",
     "iopub.status.idle": "2024-10-03T20:38:19.585430Z",
     "shell.execute_reply": "2024-10-03T20:38:19.584661Z",
     "shell.execute_reply.started": "2024-10-03T20:38:19.577956Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "del dimensions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48a931a8fbf9cff1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:55.963156Z",
     "start_time": "2025-01-13T13:08:55.960313Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:19.586724Z",
     "iopub.status.busy": "2024-10-03T20:38:19.586429Z",
     "iopub.status.idle": "2024-10-03T20:38:19.593449Z",
     "shell.execute_reply": "2024-10-03T20:38:19.592521Z",
     "shell.execute_reply.started": "2024-10-03T20:38:19.586692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def image_to_numpy(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    return np.array(image).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a386a7f8663146a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:56.017364Z",
     "start_time": "2025-01-13T13:08:56.015213Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:19.594912Z",
     "iopub.status.busy": "2024-10-03T20:38:19.594600Z",
     "iopub.status.idle": "2024-10-03T20:38:19.603715Z",
     "shell.execute_reply": "2024-10-03T20:38:19.602775Z",
     "shell.execute_reply.started": "2024-10-03T20:38:19.594879Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# setting tensor to store all images' pixels\n",
    "images = np.empty((5121, 208, 176), dtype=np.uint8)\n",
    "class_to_idx = {}\n",
    "for i in range(len(classes)):\n",
    "    class_to_idx[classes[i]] = i\n",
    "images_labels = np.empty(5121, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9031a58672823335",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:57.581074Z",
     "start_time": "2025-01-13T13:08:56.041576Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:19.605198Z",
     "iopub.status.busy": "2024-10-03T20:38:19.604899Z",
     "iopub.status.idle": "2024-10-03T20:38:24.675271Z",
     "shell.execute_reply": "2024-10-03T20:38:24.674370Z",
     "shell.execute_reply.started": "2024-10-03T20:38:19.605166Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_idx = 0\n",
    "for class_name in classes:\n",
    "    for image_name in tqdm(os.listdir(f'{train_base_dir}/{class_name}')):\n",
    "        image_path = f'{train_base_dir}/{class_name}/{image_name}'\n",
    "        images[image_idx] = image_to_numpy(image_path)\n",
    "        images_labels[image_idx] = class_to_idx[class_name]\n",
    "        image_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb37c658",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:57.629805Z",
     "start_time": "2025-01-13T13:08:57.627593Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbee4724a0832aac",
   "metadata": {},
   "source": [
    "#### Displaying heatmap for each class - whiter is stronger density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f739f8b90be1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:58.657460Z",
     "start_time": "2025-01-13T13:08:57.684958Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:24.682898Z",
     "iopub.status.busy": "2024-10-03T20:38:24.682530Z",
     "iopub.status.idle": "2024-10-03T20:38:27.379275Z",
     "shell.execute_reply": "2024-10-03T20:38:27.378257Z",
     "shell.execute_reply.started": "2024-10-03T20:38:24.682855Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10), sharey=True, sharex=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    ax = axes[i//2, i%2]\n",
    "    class_images = images[np.where(images_labels == i)]\n",
    "    heatmap = np.sum(class_images, axis=0)\n",
    "    sns.heatmap(heatmap, ax=ax, cmap='gray')\n",
    "    ax.set_title(f'Pixel Density for {classes[i]}')\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842fb3f1fb1c7ff0",
   "metadata": {},
   "source": [
    "### Drop all empty pixels to reduce dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d68d4b3eef5cd15",
   "metadata": {},
   "source": [
    "#### Using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7759918c8f4acca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:58.664845Z",
     "start_time": "2025-01-13T13:08:58.662532Z"
    }
   },
   "outputs": [],
   "source": [
    "# U, S, V_t = np.linalg.svd(images.reshape(images.shape[0], -1), full_matrices=False)\n",
    "# k = int(0.2 * images.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fd72c4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:58.683305Z",
     "start_time": "2025-01-13T13:08:58.681368Z"
    }
   },
   "outputs": [],
   "source": [
    "# S = np.diag(S)\n",
    "# svd_images = U[:, :k] @ (S[:k, :k] @ V_t[:k,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fd55136",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:58.698159Z",
     "start_time": "2025-01-13T13:08:58.696228Z"
    }
   },
   "outputs": [],
   "source": [
    "# svd_images = svd_images.reshape(*(images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38f5bbf72eab726a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:58.710737Z",
     "start_time": "2025-01-13T13:08:58.708292Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(2, 2, figsize=(10, 10), sharey=True, sharex=True)\n",
    "# fig.tight_layout()\n",
    "\n",
    "# for i in range(len(classes)):\n",
    "#     ax = axes[i//2, i%2]\n",
    "#     class_images = images[np.where(images_labels == i)] - svd_images[np.where(images_labels == i)]\n",
    "#     heatmap = np.sum(class_images, axis=0)\n",
    "#     sns.heatmap(heatmap, ax=ax, cmap='gray')\n",
    "#     ax.set_title(f'Pixel Density for {classes[i]}')\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "#     ax.get_xaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40b5fbfdad37f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:59.431526Z",
     "start_time": "2025-01-13T13:08:58.720952Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:27.381229Z",
     "iopub.status.busy": "2024-10-03T20:38:27.380668Z",
     "iopub.status.idle": "2024-10-03T20:38:28.973165Z",
     "shell.execute_reply": "2024-10-03T20:38:28.972353Z",
     "shell.execute_reply.started": "2024-10-03T20:38:27.381180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# get leftmost non empty pixel\n",
    "non_empty_pixels = np.where(images > 0)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ede76e816f03790",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:59.446212Z",
     "start_time": "2025-01-13T13:08:59.442798Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:28.974600Z",
     "iopub.status.busy": "2024-10-03T20:38:28.974271Z",
     "iopub.status.idle": "2024-10-03T20:38:28.981457Z",
     "shell.execute_reply": "2024-10-03T20:38:28.980573Z",
     "shell.execute_reply.started": "2024-10-03T20:38:28.974566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "non_empty_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cf7d6df2b16508b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:59.978561Z",
     "start_time": "2025-01-13T13:08:59.452906Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:28.983022Z",
     "iopub.status.busy": "2024-10-03T20:38:28.982703Z",
     "iopub.status.idle": "2024-10-03T20:38:29.777519Z",
     "shell.execute_reply": "2024-10-03T20:38:29.776451Z",
     "shell.execute_reply.started": "2024-10-03T20:38:28.982989Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "uppermost_pixel = np.min(non_empty_pixels[0])\n",
    "bottommost_pixel = np.max(non_empty_pixels[0])\n",
    "leftmost_pixel = np.min(non_empty_pixels[1])\n",
    "rightmost_pixel = np.max(non_empty_pixels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b55c59375db1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:59.989543Z",
     "start_time": "2025-01-13T13:08:59.986835Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:29.779116Z",
     "iopub.status.busy": "2024-10-03T20:38:29.778783Z",
     "iopub.status.idle": "2024-10-03T20:38:29.787436Z",
     "shell.execute_reply": "2024-10-03T20:38:29.786560Z",
     "shell.execute_reply.started": "2024-10-03T20:38:29.779078Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# top left\n",
    "leftmost_pixel, uppermost_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef0fecb0dbc4d1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:00.011428Z",
     "start_time": "2025-01-13T13:09:00.007542Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:29.789070Z",
     "iopub.status.busy": "2024-10-03T20:38:29.788693Z",
     "iopub.status.idle": "2024-10-03T20:38:29.795628Z",
     "shell.execute_reply": "2024-10-03T20:38:29.794691Z",
     "shell.execute_reply.started": "2024-10-03T20:38:29.789020Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# bottom right\n",
    "rightmost_pixel, bottommost_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6ceb15a5d91ea3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:00.037481Z",
     "start_time": "2025-01-13T13:09:00.034422Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:29.796985Z",
     "iopub.status.busy": "2024-10-03T20:38:29.796730Z",
     "iopub.status.idle": "2024-10-03T20:38:29.804078Z",
     "shell.execute_reply": "2024-10-03T20:38:29.803355Z",
     "shell.execute_reply.started": "2024-10-03T20:38:29.796954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dropping\n",
    "images = images[:, uppermost_pixel:bottommost_pixel+1, leftmost_pixel:rightmost_pixel+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ade300a7bb885a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:00.094297Z",
     "start_time": "2025-01-13T13:09:00.091260Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:29.805435Z",
     "iopub.status.busy": "2024-10-03T20:38:29.805090Z",
     "iopub.status.idle": "2024-10-03T20:38:29.815341Z",
     "shell.execute_reply": "2024-10-03T20:38:29.814393Z",
     "shell.execute_reply.started": "2024-10-03T20:38:29.805402Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d07cb2402a8f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:00.192019Z",
     "start_time": "2025-01-13T13:09:00.188062Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:30.171208Z",
     "iopub.status.busy": "2024-10-03T20:38:30.170912Z",
     "iopub.status.idle": "2024-10-03T20:38:30.176786Z",
     "shell.execute_reply": "2024-10-03T20:38:30.175820Z",
     "shell.execute_reply.started": "2024-10-03T20:38:30.171175Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# number of reduced dimensions\n",
    "208 * 176 - 25344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d289b6d9b7ab624b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:01.108782Z",
     "start_time": "2025-01-13T13:09:00.222314Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:30.178453Z",
     "iopub.status.busy": "2024-10-03T20:38:30.178068Z",
     "iopub.status.idle": "2024-10-03T20:38:32.520325Z",
     "shell.execute_reply": "2024-10-03T20:38:32.519353Z",
     "shell.execute_reply.started": "2024-10-03T20:38:30.178399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10), sharey=True, sharex=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    ax = axes[i//2, i%2]\n",
    "    class_images = images[np.where(images_labels == i)]\n",
    "    heatmap = np.sum(class_images, axis=0)\n",
    "    sns.heatmap(heatmap, ax=ax, cmap='gray')\n",
    "    ax.set_title(f'Heatmap for {classes[i]}')\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba913bf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:01.567045Z",
     "start_time": "2025-01-13T13:09:01.115704Z"
    }
   },
   "outputs": [],
   "source": [
    "histogram = images.mean(axis=0).flatten()\n",
    "\n",
    "ax = sns.histplot(histogram, bins=255, kde=True)\n",
    "plt.xlim([0, 255])\n",
    "plt.ylim([0, 250])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb49d763de8c81",
   "metadata": {},
   "source": [
    "#### Showing distribution of pixels in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7839e9c0148b13c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:02.672787Z",
     "start_time": "2025-01-13T13:09:01.576585Z"
    },
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:32.528083Z",
     "iopub.status.busy": "2024-10-03T20:38:32.527687Z",
     "iopub.status.idle": "2024-10-03T20:38:35.602476Z",
     "shell.execute_reply": "2024-10-03T20:38:35.601618Z",
     "shell.execute_reply.started": "2024-10-03T20:38:32.528039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "for i in range(4):\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    ax.set_title(f'Histogram for {classes[i]} class')\n",
    "    sns.histplot(images[images_labels == i].mean(axis=0).flatten(), bins=255, kde=True, ax=ax)\n",
    "    ax.set_xlim([0, 255])\n",
    "    ax.set_ylim([0, 250])\n",
    "    # ax.hist(images[:, random_pixels[i]//176, random_pixels[i]%144])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37929b927296f046",
   "metadata": {},
   "source": [
    "#### Show distribution of random pixels per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f53d8fdfd22227",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:07.108946Z",
     "start_time": "2025-01-13T13:09:02.680640Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(10, 16))\n",
    "subfigs = fig.subfigures(2, 2)\n",
    "\n",
    "random_pixels = np.random.default_rng().choice(176 * 144, size=10, replace=False)\n",
    "\n",
    "for class_idx, subfig in enumerate(subfigs.flat):\n",
    "    subfig.suptitle(f'Class {classes[class_idx]}')\n",
    "    axes = subfig.subplots(5, 2)\n",
    "    class_images = images[np.where(images_labels == class_idx)]\n",
    "    for i in range(10):\n",
    "        ax = axes[i//2, i%2]\n",
    "        ax.hist(class_images[:, random_pixels[i]//176, random_pixels[i]%144])\n",
    "        ax.set_title(f'Pixel {(random_pixels[i]//176, random_pixels[i]%144)}', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e610576",
   "metadata": {},
   "source": [
    "#### NOT normalizing the images as the decoding process is less successful when dealing with a small range of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8735c466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:07.119099Z",
     "start_time": "2025-01-13T13:09:07.117135Z"
    }
   },
   "outputs": [],
   "source": [
    "# images = images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f96c47b",
   "metadata": {},
   "source": [
    "### Show Fourier transformation of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64aad65d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:07.136283Z",
     "start_time": "2025-01-13T13:09:07.133617Z"
    }
   },
   "outputs": [],
   "source": [
    "def fourier_transformed(image, shifted=False):\n",
    "    # centering the frequency values for better visibility\n",
    "    fft_image = np.fft.fft2(image)\n",
    "    # fft_conj_image = np.conj(fft_image)\n",
    "    # # will always be non-negative real values\n",
    "    # transformed = np.real(fft_image * fft_conj_image)\n",
    "    if shifted:\n",
    "        return np.fft.fftshift(fft_image)\n",
    "    return fft_image\n",
    "\n",
    "def inverse_fourier_transformed(transformed_image, shifted=False):\n",
    "    if shifted:\n",
    "        transformed_image = np.fft.ifftshift(transformed_image)\n",
    "    # getting the rescaled spatial image, shifted\n",
    "    inverse_fft_image = np.fft.ifft2(transformed_image)\n",
    "    # inverse_fft_conj_image = np.conj(inverse_fft_image)\n",
    "    # inverse_transformed = np.real(inverse_fft_image * inverse_fft_conj_image)\n",
    "    inverse_transformed = np.real(inverse_fft_image)\n",
    "    # inverse_transformed = np.abs(inverse_fft_image)\n",
    "    # normalizing the values as norm of each pixel can be very high\n",
    "    inverse_transformed = 255 * inverse_transformed / inverse_transformed.max()\n",
    "    return inverse_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e229f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:07.849286Z",
     "start_time": "2025-01-13T13:09:07.146978Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.set_title(f'Fourier transformed heatmap for class {classes[i]}', fontsize=10)\n",
    "    class_images_mean = images[images_labels == i].mean(axis=0)\n",
    "    class_mean_fourier_transformed = fourier_transformed(class_images_mean, False)\n",
    "    ax.imshow(np.log10(np.abs(np.fft.fftshift(class_mean_fourier_transformed))), cmap='gray')\n",
    "    # ax.imshow(class_images_mean, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abaf6bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:09.640158Z",
     "start_time": "2025-01-13T13:09:07.858289Z"
    }
   },
   "outputs": [],
   "source": [
    "epsilon = 0.000001\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(12, 12))\n",
    "subfigs = fig.subfigures(2, 2)\n",
    "\n",
    "for class_idx, subfig in enumerate(subfigs.flat):\n",
    "    subfig.suptitle(f'Class {classes[class_idx]}')\n",
    "    axes = subfig.subplots(1, 2)\n",
    "    class_images = images[np.where(images_labels == class_idx)]\n",
    "    class_images_mean = images[images_labels == i].mean(axis=0)\n",
    "    class_mean_fourier_transformed = fourier_transformed(class_images_mean, False)\n",
    "    scaled_transformed = np.log10(np.abs(np.fft.fftshift(class_mean_fourier_transformed)))\n",
    "    pos0 = axes[0].imshow(scaled_transformed, cmap='gray', vmin=scaled_transformed.min(), vmax=scaled_transformed.max())\n",
    "    axes[0].set_title('Mean FT', fontsize=10)\n",
    "    fig.colorbar(pos0, ax=axes[0], shrink=0.25)\n",
    "\n",
    "    class_image = images[images_labels == i][0]\n",
    "    image_fourier_transformed_shifted = fourier_transformed(class_image, shifted=True)\n",
    "    scaled_shifted_transformed = np.log10(np.abs(image_fourier_transformed_shifted) + epsilon)\n",
    "    pos1 = axes[1].imshow(scaled_shifted_transformed, cmap='gray', vmin=scaled_shifted_transformed.min(), vmax=scaled_shifted_transformed.max())\n",
    "    axes[1].set_title('Sample FT', fontsize=10)\n",
    "    fig.colorbar(pos1, ax=axes[1], shrink=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7fb0fa2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:09.654651Z",
     "start_time": "2025-01-13T13:09:09.650799Z"
    }
   },
   "outputs": [],
   "source": [
    "ones = np.ones_like(images[0])\n",
    "epsilon = 0.000001\n",
    "border = 0\n",
    "center_y, center_x = ones.shape[0]//2, ones.shape[1]//2\n",
    "center = np.array([center_y, center_x])\n",
    "\n",
    "ones[center_y-border:center_y+border+1, center_x-border:center_x+border+1] = 0 + epsilon\n",
    "v, u = np.mgrid[:images[0].shape[0], :images[0].shape[1]]\n",
    "\n",
    "distances_from_center = np.sqrt(\n",
    "    np.square(v - center[0]) + np.square(u - center[1])\n",
    ")\n",
    "threshold = 40\n",
    "mask = distances_from_center <= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6456bbda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:12.250478Z",
     "start_time": "2025-01-13T13:09:09.668532Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(12, 12))\n",
    "subfigs = fig.subfigures(2, 2)\n",
    "\n",
    "for class_idx, subfig in enumerate(subfigs.flat):\n",
    "    subfig.suptitle(f'Class {classes[class_idx]}')\n",
    "    axes = subfig.subplots(1, 2)\n",
    "    class_images = images[np.where(images_labels == class_idx)]\n",
    "\n",
    "    class_image = class_images[0]\n",
    "    image_fourier_transformed_shifted_masked = fourier_transformed(class_image, shifted=True) * mask\n",
    "    # axes[0].imshow(np.log10(np.abs(image_fourier_transformed_shifted_masked) + epsilon), cmap='gray')\n",
    "    axes[0].imshow(class_image, cmap='gray')\n",
    "    axes[0].set_title(f'Sample FT for class {classes[class_idx]}', fontsize=10)\n",
    "\n",
    "    inverse_masked_image = np.fft.ifft2(np.fft.ifftshift(image_fourier_transformed_shifted_masked)).real\n",
    "    axes[1].imshow(inverse_masked_image, cmap='gray')\n",
    "    axes[1].set_title(f'Inverse masked sample - {classes[class_idx]}', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73cdbbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:12.916716Z",
     "start_time": "2025-01-13T13:09:12.261035Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
    "\n",
    "for i in range(4):\n",
    "    class_images = images[np.where(images_labels == i)]\n",
    "\n",
    "    class_image = class_images[0]\n",
    "    image_fourier_transformed_shifted_flattened = fourier_transformed(class_image, shifted=True).flatten() * mask.flatten()\n",
    "    axes[i//2, i%2].scatter(np.arange(image_fourier_transformed_shifted_flattened.shape[0]), np.log10(np.abs(image_fourier_transformed_shifted_flattened) + epsilon))\n",
    "    axes[i//2, i%2].set_title(f'Sample FT for class {classes[class_idx]}', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31b03a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-13T13:09:12.927576Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.set_title(f'Fourier transformed heatmap for class {classes[i]}', fontsize=10)\n",
    "    class_images_mean = images[images_labels == i].mean(axis=0)\n",
    "    class_mean_fourier_transformed = fourier_transformed(class_images_mean)\n",
    "    class_mean_inverse_fourier_transformed = inverse_fourier_transformed(class_mean_fourier_transformed)\n",
    "    ax.imshow(class_mean_inverse_fourier_transformed, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d838ba91b07739d5",
   "metadata": {},
   "source": [
    "### Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c6cfe5eb1a6a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.812836200Z",
     "start_time": "2024-12-15T14:38:00.179074Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:35.603842Z",
     "iopub.status.busy": "2024-10-03T20:38:35.603566Z",
     "iopub.status.idle": "2024-10-03T20:38:35.608497Z",
     "shell.execute_reply": "2024-10-03T20:38:35.607531Z",
     "shell.execute_reply.started": "2024-10-03T20:38:35.603810Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c15654c2452d9fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.824922400Z",
     "start_time": "2024-12-15T14:38:00.211735Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:35.610182Z",
     "iopub.status.busy": "2024-10-03T20:38:35.609846Z",
     "iopub.status.idle": "2024-10-03T20:38:35.620318Z",
     "shell.execute_reply": "2024-10-03T20:38:35.619360Z",
     "shell.execute_reply.started": "2024-10-03T20:38:35.610137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_side_by_side(first_images, second_images, first_title, second_title):\n",
    "    # plot\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(18, 10))\n",
    "    subfigs = fig.subfigures(2, 2)\n",
    "\n",
    "    for class_idx, subfig in enumerate(subfigs.flat):\n",
    "        subfig.suptitle(classes[class_idx])\n",
    "        axes = subfig.subplots(1, 2)\n",
    "\n",
    "        blurred_images = first_images[np.where(images_labels == class_idx)]\n",
    "        blurred_heatmap = np.sum(blurred_images, axis=0)\n",
    "        sns.heatmap(blurred_heatmap, ax=axes[0], cmap='gray')\n",
    "        axes[0].set_title(first_title)\n",
    "        axes[0].get_yaxis().set_visible(False)\n",
    "        axes[0].get_xaxis().set_visible(False)\n",
    "\n",
    "        original_images = second_images[np.where(images_labels == class_idx)]\n",
    "        original_heatmap = np.sum(original_images, axis=0)\n",
    "        sns.heatmap(original_heatmap, ax=axes[1], cmap='gray')\n",
    "        axes[1].set_title(second_title)\n",
    "        axes[1].get_yaxis().set_visible(False)\n",
    "        axes[1].get_xaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d04c97d098d98",
   "metadata": {},
   "source": [
    "#### Applying max filter with a 3x3 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a42af5b479d974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.825921600Z",
     "start_time": "2024-12-15T14:38:00.245102Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:35.642059Z",
     "iopub.status.busy": "2024-10-03T20:38:35.641795Z",
     "iopub.status.idle": "2024-10-03T20:38:35.650140Z",
     "shell.execute_reply": "2024-10-03T20:38:35.649140Z",
     "shell.execute_reply.started": "2024-10-03T20:38:35.642028Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_side_by_side(images, sp.ndimage.maximum_filter(images, size=3), 'originals', 'maximum filtered')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3030c09a0033fd",
   "metadata": {},
   "source": [
    "#### Minimum filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929592554ff1e77a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.838005200Z",
     "start_time": "2024-12-15T14:38:06.097198Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:35.651620Z",
     "iopub.status.busy": "2024-10-03T20:38:35.651329Z",
     "iopub.status.idle": "2024-10-03T20:38:35.659243Z",
     "shell.execute_reply": "2024-10-03T20:38:35.658344Z",
     "shell.execute_reply.started": "2024-10-03T20:38:35.651588Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_side_by_side(images, sp.ndimage.minimum_filter(images, size=3), 'originals', 'minimum filtered')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5639bee62dd983f",
   "metadata": {},
   "source": [
    "#### Sobel filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fb8116c1404129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.838005200Z",
     "start_time": "2024-12-15T14:38:11.993902Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:35.660923Z",
     "iopub.status.busy": "2024-10-03T20:38:35.660620Z",
     "iopub.status.idle": "2024-10-03T20:38:35.667917Z",
     "shell.execute_reply": "2024-10-03T20:38:35.667166Z",
     "shell.execute_reply.started": "2024-10-03T20:38:35.660889Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sobel_x_gradients = sp.ndimage.sobel(images / 255, axis=1)\n",
    "sobel_y_gradients = sp.ndimage.sobel(images / 255, axis=2)\n",
    "sobel_magnitude = np.sqrt(sobel_x_gradients ** 2 + sobel_y_gradients ** 2)\n",
    "sobel_magnitude = 255 * sobel_magnitude / np.max(sobel_magnitude)\n",
    "sobel_gradient_angle = np.arctan2(sobel_y_gradients, sobel_x_gradients)\n",
    "\n",
    "plot_side_by_side(images, sobel_magnitude, 'originals', 'sobel magnitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc330344e1b59e",
   "metadata": {},
   "source": [
    "#### Prewitt filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4773b33b8f9eeced",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.840124500Z",
     "start_time": "2024-12-15T14:38:22.934871Z"
    }
   },
   "outputs": [],
   "source": [
    "prewitt_x_gradients = sp.ndimage.prewitt(images / 255, axis=1)\n",
    "prewitt_y_gradients = sp.ndimage.prewitt(images / 255, axis=2)\n",
    "prewitt_magnitude = np.sqrt(prewitt_y_gradients ** 2 + prewitt_x_gradients ** 2)\n",
    "prewitt_magnitude = 255 * prewitt_magnitude / prewitt_magnitude.max()\n",
    "prewitt_gradient_angle = np.arctan2(prewitt_y_gradients, prewitt_x_gradients)\n",
    "\n",
    "plot_side_by_side(images, prewitt_magnitude, 'originals', 'prewitt magnitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90db90fee2a679d8",
   "metadata": {},
   "source": [
    "#### Compare prewitt with sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77734a328115768e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.842126200Z",
     "start_time": "2024-12-15T14:38:33.613196Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_side_by_side(prewitt_magnitude, sobel_magnitude, 'prewitt', 'sobel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ddb7600e6f009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.844126800Z",
     "start_time": "2024-12-15T14:38:37.094256Z"
    }
   },
   "outputs": [],
   "source": [
    "# x_start, x_end = 60, 80\n",
    "# y_start, y_end = 70, 85\n",
    "x_start, x_end = 0, images.shape[2]\n",
    "y_start, y_end = 0, images.shape[1]\n",
    "\n",
    "# test_image = images[0, y_start:y_end, x_start:x_end]\n",
    "group_idx = 1\n",
    "images_group = images[images_labels == group_idx]\n",
    "test_image = np.sum(images_group, axis=0) / len(images_group)\n",
    "# print(test_image, images[0, 84, 79])\n",
    "prewitt_test_y_gradient = sp.ndimage.prewitt(test_image, axis=0)\n",
    "prewitt_test_x_gradient = sp.ndimage.prewitt(test_image, axis=1)\n",
    "prewitt_test_magnitude = np.sqrt(prewitt_test_x_gradient ** 2 + prewitt_test_y_gradient ** 2)\n",
    "prewitt_test_magnitude = 255 * prewitt_test_magnitude / prewitt_test_magnitude.max()\n",
    "prewitt_test_gradient_angle = np.arctan2(prewitt_test_y_gradient, prewitt_test_x_gradient)\n",
    "\n",
    "y, x = np.mgrid[:y_end-y_start, :x_end-x_start]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 10))\n",
    "\n",
    "plt.setp(axes, xticks=np.arange(x_end - x_start), xticklabels=np.arange(x_start, x_end),\n",
    "         yticks=np.arange(y_end - y_start), yticklabels=np.arange(y_start, y_end))\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.yticks(rotation=45)\n",
    "\n",
    "axes[0].imshow(prewitt_test_magnitude, cmap='gray', zorder=1)\n",
    "# quiver plot is shown upside down so multiplying y coordinates and gradients by -1 for flipping the image and the arrows direction, respectively\n",
    "axes[0].quiver(x, y, prewitt_test_x_gradient, prewitt_test_y_gradient,\n",
    "            color='blue', angles='xy', scale_units='xy', units='width', scale=90, zorder=2)\n",
    "# axes[0].streamplot(x, y, sobel_test_x_gradient, sobel_test_y_gradient,\n",
    "#                    density=(test_image.shape[0]/30, test_image.shape[1]/30),\n",
    "#                    arrowsize=1, integration_direction='forward', zorder=2)\n",
    "axes[1].imshow(test_image, cmap='gray')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fabbf7697d818af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.846128700Z",
     "start_time": "2024-12-15T14:38:39.580923Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_side_by_side(sp.ndimage.laplace(images / 255, cval=0), prewitt_magnitude, 'laplace', 'prewitt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ad4820db54ebdc",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14ab2f",
   "metadata": {},
   "source": [
    "#### Rotating the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b1ec07f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.848126700Z",
     "start_time": "2024-12-15T14:38:46.008675Z"
    }
   },
   "outputs": [],
   "source": [
    "rotated_25 = sp.ndimage.rotate(images, 25, axes=(1, 2), reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f63479",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.849126Z",
     "start_time": "2024-12-15T14:38:54.077580Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_side_by_side(images, rotated_25, 'Originals', 'Rotated 25 degrees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d35db20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.851216200Z",
     "start_time": "2024-12-15T14:38:56.999362Z"
    }
   },
   "outputs": [],
   "source": [
    "# images = np.concatenate((images, rotated_25), axis=0)\n",
    "# images_labels = np.concatenate((images_labels, images_labels), axis=0)\n",
    "del rotated_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fac51af513ab0f43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.852217700Z",
     "start_time": "2024-12-15T14:38:57.034682Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot_side_by_side(images, images[..., :, ::-1], 'Original', 'Flipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a601562f8115f37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.853215200Z",
     "start_time": "2024-12-15T14:38:57.065851Z"
    }
   },
   "outputs": [],
   "source": [
    "# flipping the horizontal axis as we're assuming (getting also the -25 rotated images)\n",
    "flipped_images = images[..., ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3e29dbebbcee4479",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.854215300Z",
     "start_time": "2024-12-15T14:38:57.104421Z"
    }
   },
   "outputs": [],
   "source": [
    "images = np.concatenate((images, flipped_images), axis=0)\n",
    "images_labels = np.concatenate((images_labels, images_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17233a33dcf2582",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.856213700Z",
     "start_time": "2024-12-15T14:38:57.207780Z"
    }
   },
   "outputs": [],
   "source": [
    "images.shape, images_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825ede82967a05aa",
   "metadata": {},
   "source": [
    "#### Training a variational autoencoder for augmenting randomized corrupted data to create new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a10bf89e52834a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.858215700Z",
     "start_time": "2024-12-15T14:38:57.243571Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:35.687348Z",
     "iopub.status.busy": "2024-10-03T20:38:35.686802Z",
     "iopub.status.idle": "2024-10-03T20:38:35.695457Z",
     "shell.execute_reply": "2024-10-03T20:38:35.694606Z",
     "shell.execute_reply.started": "2024-10-03T20:38:35.687285Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7c2c6e7008cb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.859214900Z",
     "start_time": "2024-12-15T14:38:57.275699Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:35.696773Z",
     "iopub.status.busy": "2024-10-03T20:38:35.696495Z",
     "iopub.status.idle": "2024-10-03T20:38:35.706657Z",
     "shell.execute_reply": "2024-10-03T20:38:35.705810Z",
     "shell.execute_reply.started": "2024-10-03T20:38:35.696741Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cb27442c9234bd",
   "metadata": {},
   "source": [
    "#### Preparing data for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "238fc2dcd06b3867",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.861299200Z",
     "start_time": "2024-12-15T14:38:57.308304Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:35.708092Z",
     "iopub.status.busy": "2024-10-03T20:38:35.707750Z",
     "iopub.status.idle": "2024-10-03T20:38:35.716789Z",
     "shell.execute_reply": "2024-10-03T20:38:35.715999Z",
     "shell.execute_reply.started": "2024-10-03T20:38:35.708049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AlzheimerDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, np_images, np_labels, transform=None, target_transform=None):\n",
    "        self.X = torch.from_numpy(np_images).to(torch.float32).unsqueeze(dim=1) # adding the single channel\n",
    "        self.y = torch.from_numpy(np_labels)\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        self.len = len(self.X)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        images = self.X[idx]\n",
    "        labels = self.y[idx]\n",
    "        if self.transform:\n",
    "            images = self.transform(images)\n",
    "        if self.target_transform:\n",
    "            labels = self.target_transform(labels)\n",
    "        \n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f103be45b63d77",
   "metadata": {},
   "source": [
    "#### Defining encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7cd9e24bfebb07d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.862299400Z",
     "start_time": "2024-12-15T14:38:57.340516Z"
    }
   },
   "outputs": [],
   "source": [
    "# from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a19ef43c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.869298100Z",
     "start_time": "2024-12-15T14:38:57.371924Z"
    }
   },
   "outputs": [],
   "source": [
    "import modules.models\n",
    "from modules.models.models import ConvAutoEncoder, kl_divergence_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d6901528",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.869298100Z",
     "start_time": "2024-12-15T14:38:57.403111Z"
    }
   },
   "outputs": [],
   "source": [
    "perm = torch.randperm(images.shape[0])\n",
    "val_indices = perm[:int(images.shape[0] * 0.15)].numpy()\n",
    "train_indices = np.setdiff1d(np.arange(images.shape[0]), val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d6b639c60c83ffee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.871400300Z",
     "start_time": "2024-12-15T14:38:57.434552Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-03T20:38:35.718290Z",
     "iopub.status.busy": "2024-10-03T20:38:35.717926Z",
     "iopub.status.idle": "2024-10-03T20:38:35.947285Z",
     "shell.execute_reply": "2024-10-03T20:38:35.946258Z",
     "shell.execute_reply.started": "2024-10-03T20:38:35.718244Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from modules.models.dataset import AlzheimerDataset\n",
    "\n",
    "# alzheimer_dataset = AlzheimerDataset(images, images_labels)\n",
    "\n",
    "train_dataset = AlzheimerDataset(images[train_indices], images_labels[train_indices])\n",
    "val_dataset = AlzheimerDataset(images[val_indices], images_labels[val_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d333ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_dataset.y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a9f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(val_dataset.y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7583117afa0638",
   "metadata": {},
   "source": [
    "#### Using Optuna for hyperparameters optimization\n",
    "##### Initially, the tuning was manual, and I was getting ~8000 Overall loss values (MSE + lambda * KLE Div), and after changing the optimizer from Adam to SGD and tweaking the learning rate and adding dampening, it went down to ~2000. With Optuna it found a set of hyperparameters with a loss value of 600!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2608ebd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.873401900Z",
     "start_time": "2024-12-15T14:38:57.645594Z"
    }
   },
   "outputs": [],
   "source": [
    "import modules.db\n",
    "from modules.db.optuna_report import report_optuna_trial, get_best_hyperparameters, get_last_study_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "98718faf0e4fbc6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.875400900Z",
     "start_time": "2024-12-15T14:38:57.676601Z"
    }
   },
   "outputs": [],
   "source": [
    "# using tensorboard for displaying training progress and metrices in real time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36b3fb16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.877400700Z",
     "start_time": "2024-12-15T14:38:57.708175Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir('./data/studies'):\n",
    "    os.mkdir('./data/studies')\n",
    "studies_directories = os.listdir('./data/studies/')\n",
    "# if last study wasn't finished, use that study id in tensorboard and later on in resuming the optuna study\n",
    "if len(studies_directories) > 0:\n",
    "    current_study_id = studies_directories[-1].split('-')[-1]\n",
    "# last study finished successfully so we'll start a brand new one\n",
    "else:\n",
    "    current_study_id = get_last_study_id() + 1\n",
    "current_study_id = get_last_study_id() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea15f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_study_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3a938f918bfa71a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.880493700Z",
     "start_time": "2024-12-15T14:39:02.791728Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, loss, regularization_lambda, dataloader, val_dataset, overall_losses,\n",
    "                kl_divergence_losses, main_losses,val_overall_losses, val_kl_divergence_losses, val_main_losses,\n",
    "                epoch, scheduler=None, writer=None):\n",
    "    for _, (batch_X, _) in enumerate(dataloader):\n",
    "        batch_X = batch_X.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        _, batch_encoded_mean, batch_encoded_log_var, batch_decoded_output = model(batch_X)\n",
    "        # batch_decoded_output = autoencoder(batch_X)\n",
    "    \n",
    "        batch_main_loss = loss(batch_decoded_output, batch_X)\n",
    "        # batch_loss = batch_mse_loss\n",
    "        batch_kl_divergence_loss = kl_divergence_loss(batch_encoded_mean, batch_encoded_log_var)\n",
    "        batch_loss = batch_main_loss + regularization_lambda * batch_kl_divergence_loss\n",
    "    \n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            overall_losses[epoch] += batch_loss.item() * batch_X.shape[0]\n",
    "            kl_divergence_losses[epoch] += batch_kl_divergence_loss.item() * batch_X.shape[0]\n",
    "            main_losses[epoch] += batch_main_loss.item() * batch_X.shape[0]\n",
    "    \n",
    "    # updating train metrics\n",
    "    overall_losses[epoch] /= dataloader.dataset.X.shape[0]\n",
    "    kl_divergence_losses[epoch] /= dataloader.dataset.X.shape[0]\n",
    "    main_losses[epoch] /= dataloader.dataset.X.shape[0]\n",
    "\n",
    "    if writer:\n",
    "        writer.add_scalar('Overall Loss/Train', overall_losses[epoch], epoch)\n",
    "        writer.add_scalar('KL Div Loss/Train', kl_divergence_losses[epoch], epoch)\n",
    "        writer.add_scalar('MSE Loss/Train', main_losses[epoch], epoch)\n",
    "        \n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        encoded_output, encoded_mean, encoded_log_var, decoded_output = model(val_dataset.X.to(device))\n",
    "        # decoded_output = model(dataset.X.to(device))\n",
    "        loss_value = loss(decoded_output, val_dataset.X.to(device))\n",
    "        # output_loss = loss_value\n",
    "        kl_divergence_loss_value = kl_divergence_loss(encoded_mean, encoded_log_var)\n",
    "        output_loss = loss_value + regularization_lambda * kl_divergence_loss_value\n",
    "\n",
    "        val_overall_losses[epoch] = output_loss.item()\n",
    "        val_kl_divergence_losses[epoch] = kl_divergence_loss_value.item()\n",
    "        val_main_losses[epoch] = loss_value.item()\n",
    "\n",
    "        if writer:\n",
    "            writer.add_scalar('Overall Loss/Validation', val_overall_losses[epoch], epoch)\n",
    "            writer.add_scalar('KL Div Loss/Validation', val_kl_divergence_losses[epoch], epoch)\n",
    "            writer.add_scalar('MSE Loss/Validation', val_main_losses[epoch], epoch)\n",
    "            # setting image pixel values to [0, 255] range\n",
    "            image = decoded_output[0].squeeze().cpu()\n",
    "            image += torch.abs(image.min()) # incrementing (possibly negative) lowest values to be non-negative\n",
    "            # normalizing and setting in range [0, 255]\n",
    "            image /= image.max()\n",
    "            image *= 255\n",
    "            # rounding for best accuracy in pixel values (ceil and floor)\n",
    "            image = torch.round(image).to(torch.uint8)\n",
    "            # sending the required format to tensorboard (not very optimistic on actual results)\n",
    "            writer.add_image('Image/Validation', image, epoch, dataformats='HW')\n",
    "\n",
    "    # update learning rate after each epoch to have equal effect for every batch\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8ec093c503415dee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.882496200Z",
     "start_time": "2024-12-15T14:39:02.860157Z"
    }
   },
   "outputs": [],
   "source": [
    "# if trial is None we're going for multi-objective optimization or we're normally training\n",
    "def train(trial, model, optimizer, loss, epochs, regularization_lambda, dataloader, val_dataset, scheduler=None, plot=True, show_progress=True, study_id=None):\n",
    "    log_dir = f'./logs/study-{study_id}/trial-{trial.number}' if study_id else f'./logs/regular/'\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    # show the model graph\n",
    "    writer.add_graph(model, next(iter(dataloader))[0].to(device=model.device))\n",
    "    \n",
    "    overall_losses, val_overall_losses = torch.zeros(epochs), torch.zeros(epochs)\n",
    "    kl_divergence_losses, val_kl_divergence_losses = torch.zeros(epochs), torch.zeros(epochs)\n",
    "    main_losses, val_main_losses = torch.zeros(epochs), torch.zeros(epochs)\n",
    "    \n",
    "    # using tqdm has conflicts with optuna's study progress bar\n",
    "    epochs_range = tqdm(range(epochs)) if show_progress else range(epochs)\n",
    "    for epoch in epochs_range:\n",
    "        model.train()\n",
    "        \n",
    "        train_epoch(\n",
    "            model=model,\n",
    "            optimizer=optimizer, \n",
    "            loss=loss,\n",
    "            epoch=epoch,\n",
    "            regularization_lambda=regularization_lambda,\n",
    "            dataloader=dataloader,\n",
    "            val_dataset=val_dataset,\n",
    "            val_overall_losses=val_overall_losses,\n",
    "            val_kl_divergence_losses=val_kl_divergence_losses,\n",
    "            val_main_losses=val_main_losses,\n",
    "            overall_losses=overall_losses,\n",
    "            kl_divergence_losses=kl_divergence_losses,\n",
    "            main_losses=main_losses,\n",
    "            scheduler=scheduler,\n",
    "            writer=writer\n",
    "        )\n",
    "\n",
    "        writer.flush()\n",
    "        \n",
    "        if trial is not None:\n",
    "            trial.report(overall_losses[epoch].item(), epoch)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                writer.close()\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "    if plot:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(16, 6))\n",
    "\n",
    "        axes[0].plot(overall_losses.cpu(), color='blue', label='Train')\n",
    "        axes[0].plot(val_overall_losses.cpu(), color='orange', label='Validation')\n",
    "        axes[0].set_title('Overall Loss')\n",
    "        \n",
    "        axes[1].plot(kl_divergence_losses.cpu(), color='blue', label='Train')\n",
    "        axes[1].plot(val_kl_divergence_losses.cpu(), color='orange', label='Validation')\n",
    "        axes[1].set_title('KL Divergence Loss')\n",
    "        \n",
    "        axes[2].plot(main_losses.cpu(), color='blue', label='Train')\n",
    "        axes[2].plot(val_main_losses.cpu(), color='orange', label='Validation')\n",
    "        axes[2].set_title('Main Loss')\n",
    "        \n",
    "        fig.legend()\n",
    "    \n",
    "    # writer.flush()\n",
    "    writer.close()\n",
    "    \n",
    "    return (overall_losses, val_overall_losses), (kl_divergence_losses, val_kl_divergence_losses), (main_losses, val_main_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8fe65934e360bf7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.883497900Z",
     "start_time": "2024-12-15T14:39:02.900625Z"
    }
   },
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        return torch.sqrt(self.mse(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "56cce0f087e8763c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.885496700Z",
     "start_time": "2024-12-15T14:39:02.907527Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss_function(loss_idx):\n",
    "    return nn.MSELoss() if loss_idx == 0 else RMSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c6a14319acdcbbe6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.887495900Z",
     "start_time": "2024-12-15T14:39:02.945381Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_hyperparameters(trial):\n",
    "    encoded_dim = trial.suggest_int('encoded_dim', 2, 64*64)\n",
    "    initial_out_channels = trial.suggest_int('initial_out_channels', 2, 8)\n",
    "    # autoencoder = AutoEncoder(in_channels=1, encoded_dim=encoded_dim, initial_out_channels=initial_out_channels).to(device)\n",
    "\n",
    "    lr = trial.suggest_float('lr', 1e-3, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 0.1, 0.4, log=True)\n",
    "    # beta1 can be used instead of momentum (that's another name for it in the Adam optimizer) but for simplicity we'll generate them both\n",
    "    beta1 = trial.suggest_float('beta1', 0.8, 0.999)\n",
    "    beta2 = trial.suggest_float('beta2', 0.5, 0.999)\n",
    "\n",
    "    momentum = trial.suggest_float('momentum', 0, 0.5)\n",
    "    dampening = trial.suggest_float('dampening', 0, 0.5)\n",
    "\n",
    "    optimizer_idx = trial.suggest_int('optimizer_idx', 0, 1)\n",
    "\n",
    "    scheduler_gamma = trial.suggest_float('scheduler_gamma', 0.8, 0.999)\n",
    "\n",
    "    kl_divergence_lambda = trial.suggest_float('kl_divergence_lambda', 0.5, 5)\n",
    "\n",
    "    epochs = trial.suggest_int('epochs', 50, 150)\n",
    "    batch_size = trial.suggest_int('batch_size', 32, 256)\n",
    "\n",
    "    loss_idx = trial.suggest_int('loss_idx', 0, 0)\n",
    "\n",
    "    relu_slope = trial.suggest_float('relu_slope', 0, 0.1)\n",
    "\n",
    "    return encoded_dim, initial_out_channels, lr, weight_decay, (beta1, beta2), momentum, dampening, optimizer_idx, \\\n",
    "          scheduler_gamma, kl_divergence_lambda, epochs, batch_size, loss_idx, relu_slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a8982b7436fbd40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.889496700Z",
     "start_time": "2024-12-15T14:39:03.073449Z"
    }
   },
   "outputs": [],
   "source": [
    "def multi_objective(trial):\n",
    "    (encoded_dim,\n",
    "     initial_out_channels,\n",
    "     lr,\n",
    "     weight_decay,\n",
    "     betas,\n",
    "     momentum,\n",
    "     dampening,\n",
    "     optimizer_idx,\n",
    "     scheduler_gamma,\n",
    "     kl_divergence_lambda,\n",
    "     epochs,\n",
    "     batch_size,\n",
    "     loss_idx,\n",
    "     relu_slope) = initialize_hyperparameters(trial)\n",
    "    \n",
    "    autoencoder = ConvAutoEncoder(in_channels=1, encoded_dim=encoded_dim, initial_out_channels=initial_out_channels,\n",
    "                                   pooling_type='max', relu_slope=relu_slope, device=device).to(device)\n",
    "    if optimizer_idx == 0:\n",
    "        optimizer = torch.optim.Adam(autoencoder.parameters(), lr=lr, weight_decay=weight_decay, betas=betas)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(autoencoder.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum, dampening=dampening)\n",
    "    # optimizer = torch.optim.SGD(autoencoder.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum, dampening=dampening)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=scheduler_gamma)\n",
    "    loss = get_loss_function(loss_idx)\n",
    "\n",
    "    # dataset_idx = trial.suggest_int('dataset_idx', 0, 2)\n",
    "    # dataset = datasets[dataset_idx]\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    overall, kl_divergence, main_loss = train(\n",
    "        model=autoencoder,\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        epochs=epochs,\n",
    "        regularization_lambda=kl_divergence_lambda,\n",
    "        dataloader=dataloader,\n",
    "        val_dataset=val_dataset,\n",
    "        scheduler=scheduler,\n",
    "        plot=False,\n",
    "        show_progress=False,\n",
    "        trial=None,\n",
    "        study_id=current_study_id\n",
    "    )\n",
    "\n",
    "    overall_train_losses, val_overall_losses = overall\n",
    "    kl_divergence_train_losses, val_kl_divergence_train_losses = kl_divergence\n",
    "    main_train_losses, val_main_losses = main_loss\n",
    "\n",
    "    # saving the best trained model exploded the VRAM so we'll have to do with the best parameters and then retrain \n",
    "    # trial.set_user_attr(key='best_booster', value=autoencoder)\n",
    "\n",
    "    return val_kl_divergence_train_losses[-1].item(), val_main_losses[-1].item()  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b4480e2bd1bf9f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.890593900Z",
     "start_time": "2024-12-15T14:39:03.081822Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    (encoded_dim,\n",
    "     initial_out_channels,\n",
    "     lr,\n",
    "     weight_decay,\n",
    "     betas,\n",
    "     momentum,\n",
    "     dampening,\n",
    "     optimizer_idx,\n",
    "     scheduler_gamma,\n",
    "     kl_divergence_lambda,\n",
    "     epochs,\n",
    "     batch_size,\n",
    "     loss_idx,\n",
    "     relu_slope) = initialize_hyperparameters(trial)\n",
    "\n",
    "    autoencoder = ConvAutoEncoder(in_channels=1, encoded_dim=encoded_dim, initial_out_channels=initial_out_channels,\n",
    "                                   pooling_type='max', relu_slope=relu_slope, device=device).to(device)\n",
    "    if optimizer_idx == 0:\n",
    "        optimizer = torch.optim.Adam(autoencoder.parameters(), lr=lr, weight_decay=weight_decay, betas=betas)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(autoencoder.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum, dampening=dampening)\n",
    "    # optimizer = torch.optim.SGD(autoencoder.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum, dampening=dampening)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=scheduler_gamma)\n",
    "    loss = get_loss_function(loss_idx)\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    overall, _, _ = train(\n",
    "        model=autoencoder,\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        epochs=epochs,\n",
    "        regularization_lambda=kl_divergence_lambda,\n",
    "        dataloader=dataloader,\n",
    "        val_dataset=val_dataset,\n",
    "        scheduler=scheduler,\n",
    "        plot=False,\n",
    "        show_progress=False,\n",
    "        trial=trial,\n",
    "        study_id=current_study_id\n",
    "    )\n",
    "    \n",
    "    overall_train_losses, val_overall_losses = overall\n",
    "    \n",
    "    # saving the best trained model exploded the VRAM so we'll have to do with the best parameters and then retrain \n",
    "    # trial.set_user_attr(key='best_booster', value=autoencoder)\n",
    "    \n",
    "    return_value = val_overall_losses[-1].item()\n",
    "    # # if loss is RMSE, return squared value to compare same range of values with MSE\n",
    "    return np.power(return_value, 2) if loss_idx == 1 else return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cafd58c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.892597900Z",
     "start_time": "2024-12-15T14:39:03.123362Z"
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "# import nest_asyncio\n",
    "\n",
    "# mandatory for getting the event loop in a jupyter notebook to be able to run asynchronous functions\n",
    "# nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b7b8b4cad41b5553",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.893596900Z",
     "start_time": "2024-12-15T14:39:03.184225Z"
    }
   },
   "outputs": [],
   "source": [
    "async def callback(study, trial):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    task = loop.create_task(report_optuna_trial(study, trial))\n",
    "    status = await task.result()\n",
    "    print(f'Status code: {status}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "989fbcfe8c90a760",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.895595600Z",
     "start_time": "2024-12-15T14:39:03.221135Z"
    }
   },
   "outputs": [],
   "source": [
    "def optimize(is_multi_objective, study_name, n_trials=100):\n",
    "    directions = ['minimize', 'minimize'] if is_multi_objective else ['minimize']\n",
    "    objective_func = multi_objective if is_multi_objective else objective\n",
    "    \n",
    "    # creating a directory for the study to be able to store and continue where we left off\n",
    "    load_if_exists = False\n",
    "    if not os.path.isdir(f'./data/studies/augmentation/{study_name}'):\n",
    "        os.mkdir(f'./data/studies/augmentation/{study_name}')\n",
    "    else:\n",
    "        load_if_exists = True\n",
    "    # using sqlite instead of postgresql like the db we're reporting to since our infrastructure already supports reporting to the postgresql db during\n",
    "    # the trials and reporting straight from here will mess the db\n",
    "    storage_name = f'sqlite:///./data/studies/augmentation/{study_name}/{study_name}.db'\n",
    "\n",
    "    n_trials = np.clip(n_trials, 1, 200)\n",
    "\n",
    "    study = optuna.create_study(study_name=study_name, storage=storage_name, directions=directions, load_if_exists=load_if_exists)\n",
    "    # study = optuna.create_study(study_name=study_name, directions=directions)\n",
    "    study.optimize(objective_func, n_trials=n_trials, timeout=20000*(n_trials // 30), show_progress_bar=True, gc_after_trial=True, callbacks=[callback])\n",
    "\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "582405d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff72756fb41463e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.899595100Z",
     "start_time": "2024-12-15T14:39:03.228671Z"
    }
   },
   "outputs": [],
   "source": [
    "is_multi_objective = False\n",
    "study_name = f'study-{current_study_id}'\n",
    "n_trials = 50\n",
    "study = optimize(is_multi_objective=is_multi_objective, study_name=study_name, n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9de6b97e7f1b0edd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.899595100Z",
     "start_time": "2024-12-15T14:39:03.260103Z"
    }
   },
   "outputs": [],
   "source": [
    "# checking if the study variable was defined, meaning we executed a study, and we want plot data from optimization process\n",
    "studied = 'study' in vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3f9159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ec4298",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.900684900Z",
     "start_time": "2024-12-15T14:39:03.301419Z"
    }
   },
   "outputs": [],
   "source": [
    "# update the best loss value on study table with the correct dataset size to get best normalized loss value overall\n",
    "if studied:\n",
    "    # removing the study directory when study is complete\n",
    "    shutil.rmtree(f'./data/studies/augmentation/{study_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6275ebd8dd8367d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.902688Z",
     "start_time": "2024-12-15T14:39:03.332791Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna.visualization as vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7360d95dd580cb5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.904686200Z",
     "start_time": "2024-12-15T14:39:03.364329Z"
    }
   },
   "outputs": [],
   "source": [
    "if studied:\n",
    "    vis.plot_param_importances(study).show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9146992377de3f45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.905687200Z",
     "start_time": "2024-12-15T14:39:03.395471Z"
    }
   },
   "outputs": [],
   "source": [
    "if studied:\n",
    "    if is_multi_objective:\n",
    "        fig = vis.plot_optimization_history(study, target=lambda t: t.values[0], target_name='KL Divergence')\n",
    "    else:\n",
    "        fig = vis.plot_optimization_history(study)\n",
    "    fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fe6903013485d32b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.907686900Z",
     "start_time": "2024-12-15T14:39:03.428518Z"
    }
   },
   "outputs": [],
   "source": [
    "if studied:\n",
    "    if is_multi_objective:\n",
    "        fig = vis.plot_optimization_history(study, target=lambda t: t.values[1], target_name='MSE')\n",
    "    fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d5131c006247be13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.908686200Z",
     "start_time": "2024-12-15T14:39:03.459935Z"
    }
   },
   "outputs": [],
   "source": [
    "if studied:\n",
    "    if is_multi_objective:\n",
    "        fig = vis.plot_slice(study, target=lambda t: t.values[0], target_name='KL Divergence')\n",
    "    else:\n",
    "        fig = vis.plot_slice(study)\n",
    "    fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c1beab103bed00ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.910763200Z",
     "start_time": "2024-12-15T14:39:03.491427Z"
    }
   },
   "outputs": [],
   "source": [
    "if studied:\n",
    "    if is_multi_objective:\n",
    "        fig = vis.plot_slice(study, target=lambda t: t.values[1], target_name='MSE')\n",
    "    else:\n",
    "        fig = vis.plot_slice(study)\n",
    "    fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb08ff2e21991bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.912767100Z",
     "start_time": "2024-12-15T14:39:03.523109Z"
    }
   },
   "outputs": [],
   "source": [
    "if is_multi_objective or not studied:\n",
    "    (encoded_dim, \n",
    "     initial_out_channels,\n",
    "     learning_rate,\n",
    "     weight_decay,\n",
    "     betas,\n",
    "     momentum,\n",
    "     dampening,\n",
    "     optimizer_idx,\n",
    "     scheduler_gamma,\n",
    "     kl_divergence_lambda,\n",
    "     epochs,\n",
    "     batch_size,\n",
    "     relu_slope) = get_best_hyperparameters(from_last_study=studied) # get hyperparameters from the study, if studied\n",
    "    best_params = {\n",
    "        'encoded_dim': encoded_dim,\n",
    "        'initial_out_channels': initial_out_channels,\n",
    "        'lr': learning_rate,\n",
    "        'weight_decay': weight_decay,\n",
    "        'betas': betas,\n",
    "        'momentum': momentum,\n",
    "        'dampening': dampening,\n",
    "        'optimizer_idx': optimizer_idx,\n",
    "        'scheduler_gamma': scheduler_gamma,\n",
    "        'kl_divergence_lambda': kl_divergence_lambda,\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'loss_idx': 0,\n",
    "        'relu_slope': relu_slope\n",
    "    }\n",
    "else:\n",
    "    best_params = study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad4dee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.913766600Z",
     "start_time": "2024-12-15T14:39:08.607408Z"
    }
   },
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7e4219a939c0d13f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.915763800Z",
     "start_time": "2024-12-15T14:39:08.676777Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_dim = best_params['encoded_dim']\n",
    "initial_out_channels = best_params['initial_out_channels']\n",
    "relu_slope = best_params['relu_slope']\n",
    " \n",
    "autoencoder = ConvAutoEncoder(in_channels=1, encoded_dim=encoded_dim, initial_out_channels=initial_out_channels,\n",
    "                              pooling_type='max', relu_slope=relu_slope, device=device).to(device)\n",
    "encoder = autoencoder.encoder\n",
    "decoder = autoencoder.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c327a85d764834d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.915763800Z",
     "start_time": "2024-12-15T14:39:08.733774Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(p.numel() for p in autoencoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6204abcc440ed383",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.916767600Z",
     "start_time": "2024-12-15T14:39:08.765961Z"
    }
   },
   "outputs": [],
   "source": [
    "# lr = 0.008\n",
    "lr = best_params['lr']\n",
    "weight_decay = best_params['weight_decay']\n",
    "betas = (best_params.get('beta1'), best_params.get('beta2'))\n",
    "momentum = best_params['momentum']\n",
    "dampening = best_params['dampening']\n",
    "optimizer_idx = best_params.get('optimizer_idx')\n",
    "scheduler_gamma = best_params['scheduler_gamma']\n",
    "\n",
    "if optimizer_idx is not None and optimizer_idx == 0:\n",
    "    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=lr, weight_decay=weight_decay, betas=betas)\n",
    "else:\n",
    "    optimizer = torch.optim.SGD(autoencoder.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum, dampening=dampening)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=scheduler_gamma)\n",
    "# mse = nn.MSELoss()\n",
    "loss = get_loss_function(best_params['loss_idx'])\n",
    "\n",
    "# kl_divergence_lambda = 3\n",
    "kl_divergence_lambda = best_params['kl_divergence_lambda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c66fba9be30cc3a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.918765Z",
     "start_time": "2024-12-15T14:39:08.827471Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = best_params['epochs']\n",
    "batch_size = best_params['batch_size']\n",
    "# dataset_idx = best_params['dataset_idx']\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17de612222d35b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.920844900Z",
     "start_time": "2024-12-15T14:39:08.835791Z"
    }
   },
   "outputs": [],
   "source": [
    "overall, kl_divergence, main = train(\n",
    "    model=autoencoder,\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    epochs=epochs,\n",
    "    regularization_lambda=kl_divergence_lambda,\n",
    "    dataloader=dataloader,\n",
    "    val_dataset=val_dataset,\n",
    "    scheduler=scheduler,\n",
    "    plot=True,\n",
    "    trial=None\n",
    ")\n",
    "\n",
    "overall_train_losses, val_overall_losses = overall\n",
    "kl_divergence_train_losses, val_kl_divergence_train_losses = kl_divergence\n",
    "main_train_losses, val_main_losses = main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820320062dc0f12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.921849Z",
     "start_time": "2024-12-15T14:39:42.129322Z"
    }
   },
   "outputs": [],
   "source": [
    "image_to_generate = images[5121]\n",
    "# getting a generated image from the original\n",
    "with torch.no_grad():\n",
    "    # expanding the channel\n",
    "    original_batched_image = np.expand_dims(image_to_generate, axis=0)\n",
    "    # expanding batch\n",
    "    original_batched_image = np.expand_dims(original_batched_image, axis=0)\n",
    "    _, _, _, generated_image = autoencoder(torch.from_numpy(original_batched_image) \\\n",
    "                                  .to(device=device, dtype=torch.float32))\n",
    "    \n",
    "    generated_image = generated_image.flatten(start_dim=0, end_dim=2)\n",
    "    print(generated_image.shape)\n",
    "\n",
    "    laplace_filtered_generated_image = sp.ndimage.laplace(generated_image.cpu().numpy(), mode='constant', cval=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6a5839719a6580",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.923845900Z",
     "start_time": "2024-12-15T14:39:42.195032Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(16, 10), sharey=True, sharex=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "axes[0].set_title('Original')\n",
    "axes[0].imshow(image_to_generate, cmap='gray')\n",
    "axes[1].set_title('Generated')\n",
    "axes[1].imshow(generated_image.cpu(), cmap='gray')\n",
    "axes[2].set_title('Difference')\n",
    "axes[2].imshow(image_to_generate - generated_image.cpu().numpy(), cmap='gray')\n",
    "axes[3].set_title('Generated Resharpened')\n",
    "axes[3].imshow(generated_image.cpu().numpy() - laplace_filtered_generated_image, cmap='gray')\n",
    "axes[4].set_title('Resharpened Difference')\n",
    "axes[4].imshow(image_to_generate - (image_to_generate - laplace_filtered_generated_image), cmap='gray')\n",
    "(image_to_generate - generated_image.cpu().numpy()).max(), (image_to_generate - (image_to_generate - laplace_filtered_generated_image)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "219029aa6ef6262f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.924850900Z",
     "start_time": "2024-12-15T14:36:20.645362Z"
    }
   },
   "outputs": [],
   "source": [
    "single_channel_images = np.expand_dims(images, axis=1)\n",
    "# single_channels_images = dataset.X\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_images, _, _, _ = encoder(torch.from_numpy(single_channel_images).to(device=device, dtype=torch.float32))\n",
    "    encoded_images = encoded_images.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec1e864edccd2f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.926848400Z",
     "start_time": "2024-12-15T14:36:21.267991Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d6168f8b48044cbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.927849200Z",
     "start_time": "2024-12-15T14:36:21.297031Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    _, _, _, decoded_images = autoencoder(torch.from_numpy(single_channel_images).to(device=device, dtype=torch.float32))\n",
    "    decoded_images = decoded_images.cpu()\n",
    "    # laplace_filtered_decoded_images = sp.ndimage.laplace(decoded_images, mode='constant', cval=0)\n",
    "    # resharpened_decoded_images = decoded_images - laplace_filtered_decoded_images\n",
    "    # decoded_images = resharpened_decoded_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30641f7dddd99283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.929920100Z",
     "start_time": "2024-12-15T14:36:21.874558Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10), sharey=True, sharex=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    ax = axes[i//2, i%2]\n",
    "    class_images = decoded_images.squeeze().detach().numpy()[np.where(images_labels == i)]\n",
    "    heatmap = np.sum(class_images, axis=0)\n",
    "    sns.heatmap(heatmap, ax=ax, cmap='gray')\n",
    "    ax.set_title(f'Heatmap for {classes[i]}')\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f2c4d7e1f1998f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.929920100Z",
     "start_time": "2024-12-15T14:36:23.039270Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.scatter(encoded_images[:, 0], encoded_images[:, 1], c=images_labels)\n",
    "sns.histplot(encoded_images[:, 0], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db27b68cd48a18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.931974100Z",
     "start_time": "2024-12-15T14:36:23.343017Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 2, figsize=(10, 16), sharey=True, sharex=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    ax_generated = axes[i, 0]\n",
    "    ax_original = axes[i, 1]\n",
    "    generated_class_images = decoded_images.squeeze().detach().numpy()[np.where(images_labels == i)]\n",
    "    original_class_images = images[np.where(images_labels == i)]\n",
    "    original_heatmap = np.sum(original_class_images, axis=0)\n",
    "    generated_heatmap = np.sum(generated_class_images, axis=0)\n",
    "    sns.heatmap(generated_heatmap, ax=ax_generated, cmap='gray')\n",
    "    sns.heatmap(original_heatmap, ax=ax_original, cmap='gray')\n",
    "    \n",
    "    ax_generated.set_title(f'Heatmap for Decoded {classes[i]}')\n",
    "    ax_generated.get_yaxis().set_visible(False)\n",
    "    ax_generated.get_xaxis().set_visible(False)\n",
    "    \n",
    "    ax_original.set_title(f'Heatmap for {classes[i]}')\n",
    "    ax_original.get_yaxis().set_visible(False)\n",
    "    ax_original.get_xaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ff5c9938a463cb7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.933971500Z",
     "start_time": "2024-12-15T14:36:25.919625Z"
    }
   },
   "outputs": [],
   "source": [
    "from modules.models.utils import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332f9116cc034a03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.935971400Z",
     "start_time": "2024-12-15T14:36:25.951836Z"
    }
   },
   "outputs": [],
   "source": [
    "save_model(autoencoder, optimizer, best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbe03cc3749d2d7",
   "metadata": {},
   "source": [
    "#### Adding noise in the spatial domain to the encoded output and cleaning it in the frequency domain of the decoded images to create new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b800a256986d090a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.936973Z",
     "start_time": "2024-12-15T14:36:25.995650Z"
    }
   },
   "outputs": [],
   "source": [
    "# final_images = np.concatenate((np.expand_dims(images, axis=1), decoded_images), axis=0)\n",
    "final_images = np.expand_dims(images, axis=1)\n",
    "# final_labels = np.concatenate((images_labels, images_labels), axis=0)\n",
    "final_labels = images_labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a4f6496b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.938972Z",
     "start_time": "2024-12-15T14:36:26.027898Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_image(image, threshold=None):\n",
    "    fft_image = np.fft.fft2(image)\n",
    "    if threshold is None:\n",
    "        threshold = 0.0005 * np.abs(fft_image)\n",
    "    # creating a mask for zeroing low amplitudes, i.e: below the threshold\n",
    "    mask = np.ones_like(fft_image)\n",
    "    mask[np.abs(fft_image) <= threshold] = 0\n",
    "    filtered_fft_image = fft_image * mask\n",
    "    # getting the inverse fourier transform on the filtered image\n",
    "    inverse_fft_image = np.fft.ifft2(filtered_fft_image)\n",
    "    transformed_image = np.real(inverse_fft_image * np.conj(inverse_fft_image))\n",
    "    # normalizing to [0, 255] range\n",
    "    transformed_image = transformed_image / transformed_image.max()\n",
    "    \n",
    "    return transformed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b0df3dd2e4f70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.939972800Z",
     "start_time": "2024-12-15T14:36:26.059976Z"
    }
   },
   "outputs": [],
   "source": [
    "desired_min_images = 6000\n",
    "# number of times we'll add noise and decode the result\n",
    "num_iterations = desired_min_images // encoded_images.shape[0]\n",
    "\n",
    "for i in tqdm(range(num_iterations)):\n",
    "    # indices_to_reset = torch.from_numpy(np.random.choice(np.arange(encoded_dim), int(0.1 * encoded_dim), replace=False))\n",
    "    # encoded_images[:, indices_to_reset] = 0\n",
    "    encoded_noise = torch.randn(encoded_images.shape)\n",
    "    # encoded_noise = np.random.randn(*encoded_images.cpu().numpy().shape)\n",
    "    noisy_images = encoded_images + encoded_noise\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        noisy_decoded_images = decoder(noisy_images.to(device=device, dtype=torch.float32)).cpu()\n",
    "        # noisy_decoded_images = transform_image(noisy_decoded_images)\n",
    "        # laplace_filtered_noisy_decoded_images = sp.ndimage.laplace(noisy_decoded_images, mode='constant', cval=0)\n",
    "        # noisy_decoded_images = noisy_decoded_images - laplace_filtered_noisy_decoded_images\n",
    "    \n",
    "    final_images = np.concatenate((final_images, noisy_decoded_images), axis=0)\n",
    "    final_labels = np.concatenate((final_labels, images_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43de40c88d3c0d86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.941972100Z",
     "start_time": "2024-12-15T14:36:26.099512Z"
    }
   },
   "outputs": [],
   "source": [
    "final_images.shape, final_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc62958f5a66d10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.943971100Z",
     "start_time": "2024-12-15T14:36:26.132453Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 2, figsize=(10, 16), sharey=True, sharex=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    ax_generated = axes[i, 0]\n",
    "    ax_original = axes[i, 1]\n",
    "    generated_class_images = final_images.squeeze()[np.where(final_labels == i)]\n",
    "    original_class_images = images[np.where(images_labels == i)]\n",
    "    original_heatmap = np.sum(original_class_images, axis=0)\n",
    "    generated_heatmap = np.sum(generated_class_images, axis=0)\n",
    "    sns.heatmap(generated_heatmap, ax=ax_generated, cmap='gray')\n",
    "    sns.heatmap(original_heatmap, ax=ax_original, cmap='gray')\n",
    "\n",
    "    ax_generated.set_title(f'Heatmap for Decoded {classes[i]} (Total {generated_class_images.shape[0]})')\n",
    "    ax_generated.get_yaxis().set_visible(False)\n",
    "    ax_generated.get_xaxis().set_visible(False)\n",
    "\n",
    "    ax_original.set_title(f'Heatmap for {classes[i]} (Total {original_class_images.shape[0]})')\n",
    "    ax_original.get_yaxis().set_visible(False)\n",
    "    ax_original.get_xaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f246d7d298edc",
   "metadata": {},
   "source": [
    "#### Saving the decoded and generated images to disk for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7853268d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.944971300Z",
     "start_time": "2024-12-15T14:36:28.376429Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_data_directories = [dir for dir in os.listdir('./data/') if dir.startswith('decoded_data')]\n",
    "directories_nums = [int(dir.split('_')[-1]) for dir in saved_data_directories if dir.split('_')[-1].isdigit()]\n",
    "last_directory_num = max(directories_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4f040340",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.944971300Z",
     "start_time": "2024-12-15T14:36:28.409032Z"
    }
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "99ae9b64879cd632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.946972700Z",
     "start_time": "2024-12-15T14:36:28.476374Z"
    }
   },
   "outputs": [],
   "source": [
    "directory_name = f'./data/decoded_data_{last_directory_num + 1}'\n",
    "if not os.path.exists(directory_name):\n",
    "    os.mkdir(directory_name)\n",
    "    with h5py.File(f'{directory_name}/images.h5', 'w') as h5f_images_file:\n",
    "        h5f_images_file.create_dataset('images', data=final_images, dtype='i')\n",
    "\n",
    "    with h5py.File(f'{directory_name}/labels.h5', 'w') as h5f_labels_file:\n",
    "        h5f_labels_file.create_dataset('labels', data=final_labels, dtype='i')\n",
    "\n",
    "    # training dataset\n",
    "    with h5py.File(f'{directory_name}/train_images.h5', 'w') as h5f_train_images_file:\n",
    "        h5f_train_images_file.create_dataset('images', data=images[train_indices], dtype='i')\n",
    "\n",
    "    with h5py.File(f'{directory_name}/train_labels.h5', 'w') as h5f_train_labels_file:\n",
    "        h5f_train_labels_file.create_dataset('labels', data=images_labels[train_indices], dtype='i')\n",
    "\n",
    "    # validation dataset\n",
    "    with h5py.File(f'{directory_name}/val_images.h5', 'w') as h5f_val_images_file:\n",
    "        h5f_val_images_file.create_dataset('images', data=images[val_indices], dtype='i')\n",
    "\n",
    "    with h5py.File(f'{directory_name}/val_labels.h5', 'w') as h5f_val_labels_file:\n",
    "        h5f_val_labels_file.create_dataset('labels', data=images_labels[val_indices], dtype='i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b0bc558b99849d51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.947971800Z",
     "start_time": "2024-12-15T14:36:28.988255Z"
    }
   },
   "outputs": [],
   "source": [
    "del final_images\n",
    "del final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff510bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:09:14.950972600Z",
     "start_time": "2024-12-15T14:36:29.051131Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5807251,
     "sourceId": 9534819,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30776,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ml-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
